---
title: 'Using Complex Bayesian Hierarchical Models for "Detection" with Count Data'
author: "Ben Brintz"
institute: "IDEAS / VA"
format:
  revealjs:
    theme: white
    transition: fade
    autoAnimateDuration: 1.25
    autoAnimateEasing: linear
    auto-animate-unmatched: false
    incremental: true
    slideNumber: true
    css: [custom.css, uofu-theme.css]
---

## Research threads at a glance {auto-animate=true}

<div style="height:1em;"></div>

<div style="
  display: grid;
  grid-template-columns: 1fr 1fr;
  grid-template-rows: auto auto;
  gap: 3em;
  align-items: center;
  justify-items: center;
">

<!-- Top left -->
<div class="fragment" data-fragment-index="1" style="
  border:2px solid #333;
  border-radius:999px;
  padding:1.2em;
  background:#f5f7fa;
  text-align:center;
  font-weight:700;
  width: 80%;
">
Clinical Prediction &<br>Decision Support
</div>

<!-- Top right -->
<div class="fragment" data-fragment-index="2" style="
  border:2px solid #333;
  border-radius:999px;
  padding:1.2em;
  background:#f5f7fa;
  text-align:center;
  font-weight:700;
  width: 80%;
">
Design &<br>Analysis
</div>

<!-- Bottom center -->
<div class="fragment" data-fragment-index="3"
     style="grid-column: 1 / span 2; width: 100%; text-align: center;">
  <div data-id="bayes-core" style="
    border:2px solid #333;
    border-radius:999px;
    padding:1.4em;
    background:#f5f7fa;
    text-align:center;
    font-weight:800;
    width: 76%;
    max-width: 820px;
    white-space: nowrap;
    margin: 0 auto;
  ">
  Complex Bayesian Hierarchical Models in Stan<br>
  
  </div>
</div>

</div>

---

##  {auto-animate=true visibility="uncounted"}

<div style="height:1.5em;"></div>

<div style="width: 100%; text-align: center;">

<div data-id="bayes-core" style="
  border:3px solid #333;
  border-radius:999px;
  padding:2em 3em;
  background:#e8f0ff;
  text-align:center;
  font-weight:900;
  font-size:1.4em;
  width: 76%;
  max-width: 820px;
  white-space: nowrap;
  margin: 0 auto;
">
Complex Bayesian Hierarchical Models in Stan 
</div>

</div>

::: {.fragment fragment-index=2}
- Two examples of work in progress:
  - Stochastic SEIR models that incorporate imperfect **detection** - COVID-19
  - Early **detection** of call spikes - United Way 211 Calls (Food Insecurity Resources)
:::

::: {.fragment fragment-index=1}
::: {.callout-note}
SEIR models track transitions between susceptible, exposed, infectious, and removed states to represent epidemic dynamics.
:::
:::


---

## Case study 1: COVID-19 is not perfectly reported

- Latent disease transmission is never directly observed 
- Reported cases reflect testing intensity, reporting practices, and asymptomatic disease
 - Only the sickest got diagnosed with COVID-19 early in the pandemic 
- **Key capability:** separate what is happening from what is observed.


---

## Various approaches have been developed to estimate clinical detection rates {}

- **Back-calculation methods** estimate the number of infections from hospitalizations and deaths
- **Seroprevalence studies** estimate the proportion of the population that has been infected by testing for antibodies
- **Compartment models** estimate the number of infections from observed cases and the distribution of the incubation period
    - E.g. SIR (Susceptible-Infectious-Recovered) models
- **Key Challenge**: identifiability issues arise when trying to estimate both the true number of infections and the detection rate from observed data, especially when testing practices change over time.

---


## We propose a novel hierarchical Bayesian solution fit on observed county-level counts of new cases

- Latent SEIR compartmental process for true infections
  - Approximate observation using a Gaussian process
- Estimation allows for different start time across health districts
- Transmission follows a hierarchical AR(1) process over time
- Allows an evolving recovery/incubation rate (E->I and I->R transitions) using beta-binomial transition
  - Use a novel computational solution to estimate these dynamics efficiently in Stan 

::: {.fragment}
**Modeling strategy:** allow flexibility where variability is real.
:::

---

## Estimating an evolving transmission rate using a hierarchical AR(1) process

```{r,include=T,echo=F,cache=TRUE}
library(tidyverse)
library(gganimate)

log_betas_time=readRDS("betas_time.rds")[[1]]
betas_time=readRDS("betas_time.rds")[[2]] %>% mutate(n2=as.factor(n2))
p <- ggplot() +
  geom_line(data = log_betas_time, aes(x = index, y = exp(Val)), size = 1) +
  geom_ribbon(data = log_betas_time, aes(x = index, ymin = exp(Low), ymax = exp(High)),
              alpha = 0.25, fill = "grey") +
  # Use the same transformation for y if desired (here I use exp(Val) so they align with the line)
  #geom_point(data = betas_time, aes(x = index, y = Val,group=n2,color=n2), size = 2) +
  geom_line(data = betas_time %>% filter(n2 %in% 2:5), aes(x = index, y = Val,group=n2,color=n2)) + 
  labs(x = "Week", y = "Beta (transmission)") +
  theme_bw() +
  ylim(0, 5) + theme(legend.position = "none") +
  scale_color_viridis_d(begin=.25,end=.75) +
  transition_time(time)

anim=animate(p,nframes = 200, fps = 20)
#animate(p, nframes = 100, fps = 10, renderer = gifski_renderer("density_animation.gif"))

anim
```

---

## Estimating an evolving recovery rate and incubation using beta-binomial transitions 

```{r,include=T,echo=F,cache=TRUE}
library(tidyverse)
library(gganimate)

df <- readRDS("betabin_sim.rds")
colnames(df)[2] = "Binomial Transition"
colnames(df)[3] = "Beta-Binomial Transition"
p <- df %>% 
      mutate(Week = Time) %>% select(-Time) %>%
      gather(Approach, Infections,-Week) %>%
      ggplot(aes(x=Week,y=Infections,group=Approach,color=Approach)) +
        geom_point() + geom_line() +
        labs(x = "Week", y = "Infections") +
        theme_bw() + scale_color_viridis_d(begin=.25,end=.75) +
        theme(legend.position = "bottom") +
        transition_reveal(Week)

anim <- animate(p, nframes = 100, fps = 5)

anim
```

---

## Utah COVID-19 dynamics (posterior density)

![](utah_p_dens_020325.png){height=500px}

---

## Utah beta-binomial transition fit

![](utah_120525_bb.png){height=500px}

---

## Case study 2: Can spikes in 211 calls be detected early? 

- 211 is a nationwide, free public referral system that responds to >20 million requests for help each year from U.S. residents
- We have call counts from Utah from 2019 - 2025. 
- Calls are often zero or low volume, but occasionally spike when there are major events (e.g. COVID-19, natural disasters, economic shocks)
- Can we capture these spikes early to help with resource allocation and response?

---

## How we model the call data
- Zero-inflated negative binomial (ZINB) model for daily call counts
- Day-of-week effects included in both the hurdle and count components
- Latent intensity evolves through an AR(1) state process over time
- Annual seasonality represented with Fourier harmonics


::: {.fragment}
**Modeling strategy:** match distributional assumptions to observed call behavior.
:::

---

## How early warning works

- Smooth logistic change-point ramps capture medium-term structural shifts 
  - Pre-specified number but estimated using horseshoe priors to allow for flexibility
- Daily shock term captures short-lived departures from baseline

::: {.fragment}
**Capability:** separate expected temporal structure from transient anomalies.
:::

---

## Prospective model fitting from Mar 25 to Apr 10, 2020 (COVID-19 example)
```{r,include=T,echo=F,cache=TRUE}
library(tidyverse)
library(gganimate)
dat=readRDS("kappa_tau_yfit_over_dates.rds")

kappas=dat[[1]]
taus=dat[[2]]

dts=data.frame(date=seq.Date(ymd("2019-01-01"),ymd("2020-04-10"),by="day"),dt=1:466)

ts=seq(1,170,by=10) %>% purrr::map_df(function(x) {
taus[x:(x+4),]
}) %>% mutate(id=as.numeric(id))

ls=seq(6,170,by=10) %>% purrr::map_df(function(x) {
taus[x:(x+4),]
})%>% mutate(id=as.numeric(id))

ts$strength=ls %>% group_by(id) %>% mutate(strength=mean/max(mean)) %>% pull(strength)

ts=ts %>% mutate(mean=as.integer(mean)) %>%  left_join(dts,by=c("mean"="dt"))

rect_df <- ts %>%
  #filter(mean >= 153, q5 >= 153) %>%
  mutate(
    xmin = dts$date[match(round(q5), dts$dt)],
    xmax = dts$date[match(round(q95), dts$dt)],
    ci_width = q95 - q5,
    vis = scales::rescale(max(ci_width, na.rm = TRUE) - ci_width, to = c(0.05, 0.55))
  )
rect_df <- rect_df[seq(5,85,by=5),]

yfit=dat[[3]] %>% mutate(id=as.numeric(id))

y=data.frame(dt=1:466,y=dat[[4]])

yfit=yfit %>% left_join(y)
y_bar <- yfit %>%
  filter(date > ymd("2019-09-01")) %>%
  summarise(v = min(q5, na.rm = TRUE) - 0.08 * (max(q95, na.rm = TRUE) - min(q5, na.rm = TRUE))) %>%
  pull(v)
state_dates <- yfit %>%
  filter(date > ymd("2019-09-01")) %>%
  group_by(id) %>%
  summarise(latest_date = max(date, na.rm = TRUE), .groups = "drop") %>%
  mutate(label = paste0("As of ", format(latest_date, "%b %d, %Y")))


p=yfit %>% filter(date>ymd("2019-09-01")) %>% ggplot(aes(x=date,y=mean, ymin=q5, ymax=q95)) + 
  geom_line(aes(group=1), color="#4D4D4D") + geom_ribbon(aes(group=1), alpha=0.2, fill="#BDBDBD") + 
  geom_point(aes(y=y,group=1), color="#E69F00", size=1) +
  labs(title="Posterior Predictive for Call Counts in 84115",y="Call Counts",x="Day") +
  # vertical shaded interval (q5..q95) per tau
  #geom_rect(data = ts %>% filter(mean>=367), inherit.aes = FALSE,
  #          aes(xmin = q5, xmax = q95,fill=id),
  #          ymin = 0, ymax = Inf, alpha = 0.02) +
  # mean vertical lines on top
  #geom_vline(data = ts %>% filter(mean>=153), inherit.aes = FALSE, aes(xintercept = date,color=id,alpha=strength),linetype = "dashed") + 
  annotate(
    "segment",
    x = min(yfit$date[yfit$date > ymd("2019-09-01")]),
    xend = max(yfit$date),
    y = y_bar,
    yend = y_bar,
    colour = "grey80",
    linewidth = 5,
    lineend = "round"
  ) +
  geom_segment(
    data = rect_df %>% filter(mean >= 245, q5 >= 245),
    inherit.aes = FALSE,
    aes(x = xmin, xend = xmax, y = y_bar, yend = y_bar, alpha=.75, group = id),
    colour = "#009E73",
    linewidth = 7,
    lineend = "round"
  ) +
  geom_vline(
    data = state_dates,
    inherit.aes = FALSE,
    aes(xintercept = latest_date, group = id),
    linetype = "dashed",
    colour = "#0072B2",
    linewidth = 0.7,
    alpha = 0.9
  ) +
  geom_label(
    data = state_dates,
    inherit.aes = FALSE,
    aes(x = latest_date, y = Inf, label = label, group = id),
    hjust = 1.02,
    vjust = 1.6,
    size = 4.2,
    fontface = "bold",
    label.size = 0.2,
    label.r = grid::unit(0.12, "lines"),
    fill = "white",
    colour = "#1F2937"
  ) +
  scale_alpha_identity() + expand_limits(y = y_bar) + coord_cartesian(clip = "off") +
  theme_minimal() + xlab("") + 
  theme(legend.position = "none",plot.caption = element_text(size = 14),margin=margin(t=15)) +
  transition_states(id, transition_length = 4, state_length = 1, wrap = FALSE) +
  ease_aes("linear") +
  shadow_mark(past = F, future = FALSE, alpha = 0.15) #+
  #enter_null() + exit_null()

#kappas=map2_dfr(1:17,seq.Date(ymd("2020-03-25"),ymd("2020-04-10"),by="days"), function(x,y) {
#  kappas %>% filter(id==x) %>% mutate(date=seq.Date(ymd("2019-01-01"),y))
#}) %>% mutate(id=as.numeric(id))

# p=kappas %>% filter(date>ymd("2020-01-01")) %>% ggplot(aes(x=date,y=exp(mean),group=id)) + geom_point() + #+ geom_ribbon(aes(ymin=q5,ymax=q95),alpha=0.25) +
#   labs(x = "Date", y = "Kappa (structural change)") +
#   theme_bw() + scale_color_viridis_d(begin=.25,end=.75) +
#   theme(legend.position = "bottom") +
#   geom_hline(yintercept=1, linetype="dashed", color = "red") +
#   geom_hline(yintercept=1.1, linetype="dashed", color = "blue") +
#   geom_hline(yintercept=0.9, linetype="dashed", color = "blue") +
#   transition_states(id, state_length = 1, transition_length = 3, wrap = FALSE) +
#   ease_aes("cubic-in-out") +
#   enter_fade() + exit_fade()

anim <- animate(p, nframes = 100, fps = 5)

anim


```
Orange dots are observed call counts. Dark grey line and light grey shade are model fit with posterior credible intervals. Green bar near the x-axis represents 90% credible intervals for change-point timing, and the dashed blue line marks the current date.
---

## Prospective model fitting from Mar 25 to Apr 10, 2020 (COVID-19 example)

```{r,include=T,echo=F,cache=TRUE}
library(tidyverse)
library(gganimate)

dat <- readRDS("kappa_tau_yfit_over_dates.rds")
kappas <- dat[[1]]
yfit <- dat[[3]] %>% mutate(id = as.numeric(id))
y <- data.frame(dt = 1:466, y = dat[[4]])

kappas <- map2_dfr(
  1:17,
  seq.Date(ymd("2020-03-25"), ymd("2020-04-10"), by = "days"),
  function(i, asof_date) {
    kappas %>%
      filter(id == i) %>%
      mutate(date = seq.Date(ymd("2019-01-01"), asof_date, by = "days"))
  }
) %>% mutate(id = as.numeric(id))

yfit_plot <- yfit %>%
  left_join(y, by = "dt") %>%
  filter(date > ymd("2020-01-01"))

kappa_plot <- kappas %>%
  filter(date > ymd("2020-01-01")) %>%
  transmute(
    id,
    date,
    mean = exp(mean),
    q5 = NA,
    q95 = NA,
    y = as.numeric(NA),
    panel = "Posterior kappa over time"
  )

fit_plot <- yfit_plot %>%
  transmute(
    id,
    date,
    mean,
    q5,
    q95,
    y,
    panel = "Observed calls and posterior fit"
  )

plot_dat <- bind_rows(kappa_plot, fit_plot)
plot_dat$panel <- factor(
  plot_dat$panel,
  levels = c("Observed calls and posterior fit", "Posterior kappa over time")
)

p <- ggplot(plot_dat, aes(x = date, y = mean, ymin = q5, ymax = q95, group = id)) +
  geom_point(data = plot_dat %>% filter(panel == "Posterior kappa over time"),
             color = "#0072B2", size = 2.1, alpha = 0.95) +
  geom_hline(data = tibble(panel = "Posterior kappa over time", yint = c(1.0, 1.1, 0.9)),
             aes(yintercept = yint), inherit.aes = FALSE,
             linetype = c("dashed", "dotted", "dotted"),
             color = c("#D55E00", "grey40", "grey40"), linewidth = 0.6) +
  geom_ribbon(data = plot_dat %>% filter(panel == "Observed calls and posterior fit"),
              fill = "grey75", alpha = 0.3) +
  geom_line(data = plot_dat %>% filter(panel == "Observed calls and posterior fit"),
            color = "grey25", linewidth = 0.8) +
  geom_point(data = plot_dat %>% filter(panel == "Observed calls and posterior fit"),
             aes(y = y), color = "#E69F00", size = 0.9, alpha = 0.85) +
  geom_blank(
    data = tibble(
      panel = factor("Posterior kappa over time", levels = levels(plot_dat$panel)),
      date = min(plot_dat$date, na.rm = TRUE),
      mean = c(0.5, 1.5)
    ),
    aes(x = date, y = mean),
    inherit.aes = FALSE
  ) +
  geom_label(
    data = state_dates,
    inherit.aes = FALSE,
    aes(x = latest_date, y = Inf, label = label, group = id),
    hjust = 1.02,
    vjust = 1.6,
    size = 4.2,
    fontface = "bold",
    label.size = 0.2,
    label.r = grid::unit(0.12, "lines"),
    fill = "white",
    colour = "#1F2937"
  ) + 
  geom_vline(
    data = state_dates,
    inherit.aes = FALSE,
    aes(xintercept = latest_date, group = id),
    linetype = "dashed",
    colour = "#0072B2",
    linewidth = 0.7,
    alpha = 0.9
  ) +
  facet_wrap(~panel, ncol = 1, scales = "free_y", axes = "all_x", axis.labels = "all") +
  labs(x = "Day", y = NULL) +
  theme_bw(base_size = 13) +
  theme(legend.position = "none",
        strip.text = element_text(face = "bold")) +
  transition_states(id, transition_length = 4, state_length = 1, wrap = FALSE) +
  ease_aes("linear") +
  shadow_mark(past = FALSE, future = FALSE, alpha = 0.15)

animate(p, nframes = 100, fps = 5)
```

Top panel overlays raw calls (orange points) with posterior mean and 90% credible interval.
Bottom panel shows posterior kappa points with reference lines at 1.0 and +/-10% (y-axis fixed to 0.5-1.5).

---

## Practical decision use

- Posterior expected calls are compared against latent baseline expectations
- Probabilistic surge metrics support threshold-based operational alerting
- Thresholds can be tuned using lead-time versus false-alarm tradeoffs

---

## What unifies this work

- Latent-process Bayesian models with temporal dependence
- Flexible distributions matched to real-world count data
- Early detection through probabilistic change modeling

---

## Current focus areas

- Early detection under delayed, zero-inflated, and overdispersed data
- Adaptive hierarchical models for evolving systems
- Decision-focused uncertainty rather than point predictions

---

## Looking ahead

- Integrating causal reasoning with hierarchical prediction
- Adaptive monitoring for rapid response
- Decision support that anticipates equity impacts

---

## Thank you

Questions or collaborations welcome.
